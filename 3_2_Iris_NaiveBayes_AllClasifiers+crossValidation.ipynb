{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JMartinArocha/MasterBigData/blob/main/3_2_Iris_NaiveBayes_AllClasifiers%2BcrossValidation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importación de datos\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "iris = sns.load_dataset('iris')\n",
        "\n",
        "# 1. Creamos un array con los distintos clasificadores\n",
        "clasificadores = [MultinomialNB(), GaussianNB(),ComplementNB(),BernoulliNB(), CategoricalNB()]\n",
        "print('Sin Cross Validation')\n",
        "# Ejecutamos con cada clasificador\n",
        "for clasificador in clasificadores:\n",
        "    # separamos datos de entrada y salida\n",
        "    X_iris = iris.drop('species', axis=1)\n",
        "    y_iris = iris['species']\n",
        "    # separamos train y test\n",
        "    Xtrain, Xtest, ytrain, ytest = train_test_split(X_iris, y_iris, test_size=0.33, random_state=1)\n",
        "\n",
        "    nombre_clasificador = clasificador.__class__.__name__\n",
        "    # 2. instanciamos el modelo\n",
        "    model = clasificador\n",
        "    # 3. Entrenamiento con los datos\n",
        "    model.fit(Xtrain, ytrain)\n",
        "    # 4. Predicción con nuevos datos\n",
        "    y_model = model.predict(Xtest)\n",
        "\n",
        "    # 5 evaluación\n",
        "    # Compara si los resultados obtenidos por el modelo (y_model) coinciden con los datos y_test esperados\n",
        "    score = accuracy_score(ytest, y_model) # Precisión del modelo\n",
        "    print(f\"Modelo: {nombre_clasificador} Score: {score}\")\n",
        "\n",
        "    # Y finalmente visualizamos la Matriz de Confusión, para lo que se crea la siguiente función, que se llamará más adelante\n",
        "\n",
        "    # y_true : dataframe -> Los valores de las clases que son ciertos (test)\n",
        "    # y_pred : ndarray   -> Los valores calculados de las clases después de realizar la predicción\n",
        "    # class  : ndarray   -> Los nombres de las clases/valores objetivos\n",
        "\n",
        "    def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                            normalize=False,\n",
        "                            title=None,\n",
        "                            cmap=plt.cm.Blues,\n",
        "                            titleSup=None):\n",
        "        \"\"\"\n",
        "        This function prints and plots the confusion matrix.\n",
        "        Normalization can be applied by setting `normalize=True`.\n",
        "        \"\"\"\n",
        "        if not title:\n",
        "            if normalize:\n",
        "                title = 'Normalized confusion matrix'\n",
        "            else:\n",
        "                title = 'Confusion matrix, without normalization'\n",
        "\n",
        "        # Compute confusion matrix\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        # Only use the labels that appear in the data\n",
        "        classes = classes[unique_labels(y_true, y_pred)]\n",
        "        if normalize:\n",
        "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            # print(\"Normalized confusion matrix\")\n",
        "        # else:\n",
        "            # print('Confusion matrix, without normalization')\n",
        "\n",
        "        # print(cm)\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        ax.figure.colorbar(im, ax=ax)\n",
        "        # We want to show all ticks...\n",
        "        ax.set(xticks=np.arange(cm.shape[1]),\n",
        "            yticks=np.arange(cm.shape[0]),\n",
        "            # ... and label them with the respective list entries\n",
        "            xticklabels=classes, yticklabels=classes,\n",
        "            title=title,\n",
        "            ylabel='True label',\n",
        "            xlabel='Predicted label')\n",
        "\n",
        "        # Rotate the tick labels and set their alignment.\n",
        "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "                rotation_mode=\"anchor\")\n",
        "\n",
        "        # Loop over data dimensions and create text annotations.\n",
        "        fmt = '.2f' if normalize else 'd'\n",
        "        thresh = cm.max() / 2.\n",
        "        for i in range(cm.shape[0]):\n",
        "            for j in range(cm.shape[1]):\n",
        "                ax.text(j, i, format(cm[i, j], fmt),\n",
        "                        ha=\"center\", va=\"center\",\n",
        "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        fig.tight_layout()\n",
        "        fig.suptitle(titleSup, fontsize=16, y=1, ha='center')\n",
        "        return ax\n",
        "\n",
        "    # Transformamos variables categóricas a valores numéricos/enteros para llamar a la función que pinta la matriz de confusión plot_confusion_matrix()\n",
        "    ytest_df= ytest.to_frame()\n",
        "    ytest_df['species'].replace(['setosa', 'versicolor', 'virginica'],[0, 1, 2], inplace=True)\n",
        "\n",
        "    # Transformamos variables categóricas a array para poder llamar a la función que pinta la matriz de confusión plot_confusion_matrix()\n",
        "    # Transformamos el resultado de la predicción(array) a un dataframe para transformar los valores categóricos en numéricos\n",
        "    y_model_df= pd.DataFrame(y_model, columns = ['species'])\n",
        "    y_model_df['species'].replace(['setosa', 'versicolor', 'virginica'],[0, 1, 2], inplace=True)\n",
        "    # Y volvemos a transformar el dataframe a un array, que es el tipo de dato que espera la función plot_confusion_matrix()\n",
        "    y_model_array = y_model_df['species'].to_numpy()\n",
        "\n",
        "    # Creamos este array porque es el parámetro con las clases que espera la función\n",
        "    # clases_iris = np.array(['setosa', 'versicolor', 'virginica'])\n",
        "    # nombre_clasificador = f\"{clasificador.__class__.__name__} Score: {score}\"\n",
        "    # plot_confusion_matrix(ytest_df['species'], y_model_array, classes=clases_iris, normalize=False, title='Normalized confusion matrix', titleSup=nombre_clasificador)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7qtTuVOaxsy",
        "outputId": "7b4b7f60-b07b-4409-98c5-ebb682cb5b05"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sin Cross Validation\n",
            "Modelo: MultinomialNB Score: 0.64\n",
            "Modelo: GaussianNB Score: 0.94\n",
            "Modelo: ComplementNB Score: 0.62\n",
            "Modelo: BernoulliNB Score: 0.28\n",
            "Modelo: CategoricalNB Score: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Añadimos cross validation\n",
        "crossValidation = KFold(n_splits = 5, shuffle = True) # shuffle = False si hay dimensión temporal\n",
        "\n",
        "total_scores = []\n",
        "for clasificador in clasificadores:\n",
        "  Xtrain, Xtest, ytrain, ytest = train_test_split(X_iris, y_iris, test_size=0.33, random_state=1)\n",
        "\n",
        "  model = clasificador\n",
        "  fold_accuracy = []\n",
        "  for train_fold, test_fold in crossValidation.split(Xtrain):\n",
        "      # División train test aleatoria\n",
        "      f_train_x = Xtrain.iloc[train_fold] # Extrae la información (iloc), atendiendo a los indices obtenidos por CrossValidation\n",
        "      f_train_y = ytrain.iloc[train_fold]\n",
        "      # entrenamiento\n",
        "      model.fit(f_train_x, f_train_y)\n",
        "      # Realizamos la predicción (Final evaluation) y guardamos la precisión para calcular la media posteriormente\n",
        "      y_pred = model.predict(Xtrain.iloc[test_fold])\n",
        "      # evaluación del modelo\n",
        "      acc = accuracy_score(ytrain.iloc[test_fold], y_pred)\n",
        "      fold_accuracy.append(acc)\n",
        "\n",
        "  total_scores.append(sum(fold_accuracy)/len(fold_accuracy))\n",
        "print('Con Cross Validation')\n",
        "for i in range(len(clasificadores)):\n",
        "    nombre_clasificador = f\"{clasificadores[i].__class__.__name__}\"\n",
        "    print(f\"Modelo: {nombre_clasificador} Score: {total_scores[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSvNGu6nlgJW",
        "outputId": "b1a7dd5a-f975-4cf9-df64-8899ba0f0641"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Con Cross Validation\n",
            "Modelo: MultinomialNB Score: 0.8099999999999999\n",
            "Modelo: GaussianNB Score: 0.93\n",
            "Modelo: ComplementNB Score: 0.6900000000000001\n",
            "Modelo: BernoulliNB Score: 0.19\n",
            "Modelo: CategoricalNB Score: 0.9100000000000001\n"
          ]
        }
      ]
    }
  ]
}